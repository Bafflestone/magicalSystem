
# LLM configs
use_local_llm=False
ollama_llm="qwen2.5:7b"
openai_llm="gpt-4o"

# Storage paths
dnd_converter_outputs_name = "dnd_converter_outputs"